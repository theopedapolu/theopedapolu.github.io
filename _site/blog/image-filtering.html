<!DOCTYPE html>

<!--
  portfolYOU Jekyll theme by yousinix
  Free for personal and commercial use under the MIT license
  https://github.com/yousinix/portfolYOU
-->

<html lang="en" class="h-100">

<head>

  
  
  

  

  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <meta property="og:type" content="website">
  <meta property="og:title" content="Experimenting with image filters and blending techniques">
  <meta property="og:description" content=""Good procrastination is avoiding errands to do real work" - Paul Graham. TODO: Write a clever welcome message">
  <meta property="og:image" content="https://i.postimg.cc/vTPwH7kx/profile.jpg">

  <title>Experimenting with image filters and blending techniques</title>
  <meta name="description" content=""Good procrastination is avoiding errands to do real work" - Paul Graham. TODO: Write a clever welcome message">

  <link rel="shortcut icon" type="image/x-icon" href="/assets/favicon.ico">

  <!-- Theme style -->
  <script src="/assets/js/theme.js"></script>

  <!-- Font Awesome CDN -->
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.4/css/all.css">

  <!-- Bootstrap CSS CDN -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.0/dist/css/bootstrap.min.css">

  <!-- Animate CSS CDN -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.7.0/animate.css">

  <!-- Custom CSS -->
  <link rel="stylesheet" href="/assets/css/style.css">

</head>


<body class="h-100 d-flex flex-column">

  <main class="flex-shrink-0 container mt-5">
    <nav class="navbar navbar-expand-lg navbar-themed">

  <a class="navbar-brand" href="/"><h5><b>Theophilus Pedapolu</b></h5></a>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation">
    <i class="fas fa-1x fa-bars text-themed"></i>
  </button>

  <div class="collapse navbar-collapse" id="navbarNavAltMarkup">
    <div class="navbar-nav ml-auto"><a class="nav-item nav-link " href="/projects/">Projects</a>

      <a class="nav-item nav-link active" href="/blog/">Blog</a>

      <a class="nav-item nav-link " href="/about/">About</a>

      

      <span id="theme-toggler" class="nav-item nav-link" role="button" onclick="toggleTheme()"></span>
    </div>
  </div>

</nav>
    <div class="col-lg-10 mx-auto mt-5 markdown-body">
  <h1><b>Experimenting with image filters and blending techniques</b></h1>

<p class="post-metadata text-muted">
  28 October 2023 -  
  <b>6 mins read time</b>

  <br>Tags: 
    
    <a class="text-decoration-none no-underline" href="/blog/tags#photography">
      <span class="tag badge badge-pill text-primary border border-primary">Photography</span>
    </a>
    
    <a class="text-decoration-none no-underline" href="/blog/tags#image-processing">
      <span class="tag badge badge-pill text-primary border border-primary">Image Processing</span>
    </a>
    </p>

<h2 id="background">Background</h2>

<p>In this project, we explore various use cases of filters/convolution and
the frequency domain of images. Part 1 (and Part 2.1) explores various
edge detection schemes using filters and Part 2 mainly uses the
frequency domain of images to perform some interesting tasks.</p>

<h2 id="part-1-filters">Part 1: Filters</h2>

<h3 id="11-finite-difference-operator">1.1 Finite Difference Operator</h3>

<p>First, we use the simple finite difference operators to perform edge
detection on the cameraman image. In particular, we convolve the filters
D_x = [-1 1] and D_y = [1 -1]^T^ with the cameraman image to get the
partial derivatives of the x and y directions, as shown below. To
combine this into one edge-detected image, we perform a gradient
magnitude computation as follows: res(i,j) = sqrt(cameraman_dx(i,j)^2^ +
cameraman_dy(i,j)^2^) where res is the output image, cameraman_dx is the
convolution of the cameraman image with D_x, and cameraman_dy is the
convolution with D_y. This uses the partial derivatives of the x and y
directions to find the gradient magnitude for the image. As seen below,
this creates a better edge detection overall that accounts for edges in
all directions. Finally, to make the edge detection more clear, we
binarize the gradient magnitude image by setting all pixels above 50 to
255 and pixels at or below 50 to 0. We tested out different thresholds
and found 50 worked well.</p>

<p><img src="https://i.postimg.cc/63JTf0yJ/im1.png" alt="Cameraman Original Image" /></p>

<h3 id="12-derivative-of-gaussian-dog-filter">1.2 Derivative of Gaussian (DoG) Filter</h3>

<p>With the finite difference operator, the results were a little noisy and
had jagged edges, as seen in the binarized image. To get smoother edge
detection, we blur the original image by convolving it with a 2D
gaussian kernel, then performing the same edge detection scheme with the
finite difference operators.</p>

<p><img src="https://i.postimg.cc/bNNrgdNJ/im2.png" alt="Cameraman Original Image" /></p>

<p>As seen in the images above, there are clear differences between naively
applying the finite difference filters (like in part 1.1) and blurring
with a gaussian filter first then applying the finite difference
filters. The edge-detected images from this part are much smoother than
in the previous part, especially in the binarized images. The camerman
no longer has jagged edges and instead has smooth, continuous edges.
Furthermore, using the properties of convolution, we can combine the
blurring and derivative filters into a single filter called the
Derivative of Gaussian filter (DoG) which we only need to convolve once
with the cameraman image to perform smooth edge-detection. The results
of applying the DoG filter are shown below; notice they are exactly the
same as the images above.</p>

<p><img src="https://i.postimg.cc/8cw5DgwN/im3.png" alt="Cameraman DoG Filter" />
<img src="https://i.postimg.cc/qBc6Q9sm/im4.png" alt="Cameraman DoG Filter" /></p>

<h2 id="part-2-frequencies">Part 2: Frequencies</h2>

<h3 id="21-image-sharpening">2.1 Image Sharpening</h3>

<p>Now we try to use filters to sharpen an image, which means making the
edges more “defined”. To do this, we get the high frequencies of an
image by applying a gaussian filter to blur the image (i.e get the low
frequencies) then subtracting the blurred image from the original image.
This leaves only the high frequencies (mostly edges) which we then add
back to the original image to obtain a sharpened image. We also use a
parameter alpha which controls how much the image is sharpened.
Mathematically, sharpened_image(i,j) = alpha<em>original_image(i,j) +
(alpha-1)</em>blurred_image(i,j). Furthermore, we can combine the gaussian
filter and subtraction into a single filter called the unsharp mask
filter by computing alpha<em>e - (alpha-1)</em>gaussian_filter, where e is
the unit impulse (a kernel with 1 in the middle and zeros elsewhere).
The progression of sharpening some images is shown below.</p>

<p><img src="https://i.postimg.cc/SKzJ95Qf/im5.png" alt="Sharpened Image" />
<img src="https://i.postimg.cc/2SyqkyPJ/im6.png" alt="Sharpened Image" /></p>

<p>For evaluation purposes, we also blurred an image and tried to sharpen it
again. The results are shown below:</p>

<p><img src="https://i.postimg.cc/RVM6YXGv/im7.png" alt="Sharpened Image" />
<img src="https://i.postimg.cc/d1YtyVxJ/im8.png" alt="Sharpened Image" /></p>

<h3 id="22-hybrid-images">2.2 Hybrid Images</h3>

<p>To create hybrid images, we combined the low frequencies from one image
with the high frequencies from another. In particular, to compute the
low frequencies for image A, we convolved image A with a gaussian kernel
to blur it. To compute the high frequencies for image B, we computed the
low frequencies using a gaussian kernel and subtracted it from the
original image. Then we averaged the low frequency image A with the high
frequency image B to get the hybrid image. We had to experiment with the
kernel sizes and the sigmas (cutoff frequencies) for each gaussian
filter to get the most aesthetically pleasing result.</p>

<p><img src="https://i.postimg.cc/7hBxdMYL/im9.png" alt="Hybrid Image" />
<img src="https://i.postimg.cc/0yhN9fGM/im10.png" alt="Hybrid Image" />
<img src="https://i.postimg.cc/1z63XqMW/im11.png" alt="Hybrid Image" /></p>

<p>Here are the FFT plots for the Tigrence hybrid image:</p>

<p><img src="https://i.postimg.cc/NfJMzY5x/im12.png" alt="FFT Tigrence Hybrid" /></p>

<p>Here is an example of a failed hybrid image, a school bus and a giraffe.
The school bus is too short for the giraffe so the output looks strange:</p>

<p><img src="https://i.postimg.cc/0yzQg3S1/im13.png" alt="Failed Hybrid Image" /></p>

<h3 id="23-gaussian-and-laplacian-stacks">2.3 Gaussian and Laplacian Stacks</h3>

<p>We used Gaussian and Laplacian Stacks to blend an apple and an orange
image. In our procedure, we first created the gaussian stacks for the
apple and the orange by successively blurring the images with gaussian
filters that doubled in sigma at each level. We had 6 levels overall.
Then, to create the laplacian stacks for these images, we subtracted
consecutive levels of the gaussian stacks (i.e. gaussian_stack[i] -
gaussian_stack[i+1]). Furthermore, we made the gaussian stack for the
mask as well. Finally, to blend the image, we created a laplacian stack
for the output via the formula laplacian_output(i,j) =
gaussian_mask(i,j)<em>laplacian_apple(i,j) +
(1-gaussian_mask(i,j))</em>laplacian_orange(i,j) at each level. That is, we
weight the laplacians of both images by the gaussian of the mask at each
level. To get the output image, we collapse the output laplacian stack
by summing across all the levels. The result is a smoothly blended
oraple.</p>

<p><img src="https://i.postimg.cc/NMkG7v3m/im14.png" alt="Gaussian and Laplacian Stacks" />
<img src="https://i.postimg.cc/zvDzxPNM/im15.png" alt="Gaussian and Laplacian Stacks" />
<img src="https://i.postimg.cc/5N09vGnQ/im16.png" alt="Gaussian and Laplacian Stacks" />
<img src="https://i.postimg.cc/XNx7r3c0/im17.png" alt="Gaussian and Laplacian Stacks" /></p>

<h3 id="24-multiresolution-blending">2.4 Multiresolution Blending</h3>

<p>We also selected our own images to blend and used irregular masks during the blending process. We followed the same procedure for blending as outlined in the previous section for the oraple, except now with irregular masks. For example, here is the blending process of an image of Toothless (the dragon from “How to Train your Dragon”) and an image of SF’s Golden Gate Bridge:</p>

<p><img src="https://i.postimg.cc/nc0jfBwB/im18.png" alt="Multiresolution Blending" />
<img src="https://i.postimg.cc/k4QG1bbV/im19.png" alt="Multiresolution Blending" /></p>

<p>Here is the blending process of an image of Bill Gates walking and an image of Sather Gate at UC Berkeley. The blended image shows Bill walking in Sather Gate:</p>

<p><img src="https://i.postimg.cc/zDk3TTN6/im20.png" alt="Multiresolution Blending" />
<img src="https://i.postimg.cc/zvqB9GCx/im21.png" alt="Multiresolution Blending" /></p>



</div>
  </main>
  <footer class="mt-auto py-3 text-center">

  <small class="text-muted mb-2">
    <i class="fas fa-code"></i> with <i class="fas fa-heart"></i>
    by <strong>Theophilus Pedapolu</strong>
  </small>

  <div class="container-fluid justify-content-center"><a class="social mx-1"  href="mailto:theopedapolu@gmail.com"
       style="color: #6c757d"
       onMouseOver="this.style.color='#db4437'"
       onMouseOut="this.style.color='#6c757d'">
      <i class="fas fa-envelope fa-1x"></i>
    </a><a class="social mx-1"  href="https://www.github.com/theopedapolu"
       style="color: #6c757d"
       onMouseOver="this.style.color='#333333'"
       onMouseOut="this.style.color='#6c757d'">
      <i class="fab fa-github fa-1x"></i>
    </a><a class="social mx-1"  href="https://www.linkedin.com/in/theopedapolu/"
       style="color: #6c757d"
       onMouseOver="this.style.color='#007bb5'"
       onMouseOut="this.style.color='#6c757d'">
      <i class="fab fa-linkedin-in fa-1x"></i>
    </a><a class="social mx-1"  href="https://www.twitter.com/TPedapolu"
       style="color: #6c757d"
       onMouseOver="this.style.color='#1da1f2'"
       onMouseOut="this.style.color='#6c757d'">
      <i class="fab fa-twitter fa-1x"></i>
    </a>

</div><small id="attribution">
    theme <a href="https://github.com/yousinix/portfolYOU">portfolYOU</a>
  </small>

</footer>

  
  <!-- GitHub Buttons -->
<script async defer src="https://buttons.github.io/buttons.js"></script>

<!-- jQuery CDN -->
<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>

<!-- Popper.js CDN -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js"></script>

<!-- Bootstrap JS CDN -->
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js"></script>

<!-- wow.js CDN & Activation -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/wow/1.1.2/wow.js"></script>
<script> new WOW().init(); </script>

<!-- Initialize all tooltips -->
<script>
$(function () {
    $('[data-toggle="tooltip"]').tooltip()
})
</script>
</body>

</html>